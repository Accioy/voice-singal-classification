{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 训练样本路径\n",
    "\n",
    "# 此处修改\n",
    "ROOT_DIR=os.path.abspath('.')\n",
    "wav_path = os.path.join(ROOT_DIR,\"hd_signal_keras_train\")\n",
    "# wav_path = 'E:/Dataset/hd_signal_keras_train'\n",
    "# 获得训练用的wav文件路径列表\n",
    "def get_wav_files(wav_path=wav_path):\n",
    "    wav_files = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(wav_path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):\n",
    "                filename_path = os.sep.join([dirpath, filename])\n",
    "                if os.stat(filename_path).st_size < 240000:  # 剔除掉一些小文件\n",
    "                    continue\n",
    "                wav_files.append(filename_path)\n",
    "    return wav_files\n",
    "\n",
    "\"\"\"\n",
    "文件名的形式是\n",
    "\n",
    "wav_files[4].split(\"\\\\\")\n",
    "['wav/train', 'A11', 'A11_101.WAV']\n",
    "A11就是编号A11的人说的话了\n",
    "\n",
    "然后需要抽取这些语音的mfcc特征,这里借助一个python_speech_features的库来取,\n",
    "根据某一篇论文的描述，此处不光抽取了13阶mfcc特征，还抽取了这13阶特征的一阶差值和二阶差值，一共是39维特征：\n",
    "\"\"\"\n",
    "\n",
    "wav_files = get_wav_files()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import librosa\n",
    "import numpy as np\n",
    "import python_speech_features\n",
    "import scipy\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "from sklearn import preprocessing\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "begin_time = time.time()\n",
    "for i, onewav in enumerate(wav_files):\n",
    "    if i % 5 == 4:  # 运行5个路径名后。\n",
    "        gaptime = time.time() - begin_time\n",
    "        percent = float(i) * 100 / len(wav_files)\n",
    "        eta_time = gaptime * 100 / (percent + 0.01) - gaptime\n",
    "        strprogress = \"[\" + \"=\" * int(percent // 2) + \">\" + \"-\" * int(50 - percent // 2) + \"]\"\n",
    "        str_log = (\"%.2f %% %s %s/%s \\t used:%d s  eta:%d s\" % (percent, strprogress, i, len(train_y), gaptime, eta_time))\n",
    "        sys.stdout.write('\\r' + str_log)\n",
    "\n",
    "    elements = onewav.split(\"\\\\\")\n",
    "    for x in elements:\n",
    "        if (x == 'metalnode' or x == 'diode'):\n",
    "            label = x\n",
    "\n",
    "\n",
    "    (rate, sign) = wav.read(onewav)\n",
    "\n",
    "    # for i in range(len(sign)):\n",
    "    #     if sign[i, 0] > 10 or sign[i, 1] < -10:\n",
    "    #         sig = sign[i:(i + 220500)].copy()\n",
    "    #         break\n",
    "    # 需加入音频分段程序。添加对应标签！！！！\n",
    "    # mfcc_feat = mfcc(scipy.signal.resample(sig, len(sig) // 2), rate // 2)  # 使用FFT重采样n个点。\n",
    "    mfcc_feat = mfcc(scipy.signal.resample(sign, len(sign) // 2), rate // 2)\n",
    "\n",
    "    mfcc_feat_div = np.concatenate((mfcc_feat[[0]], mfcc_feat[:-1]))  # 数组拼接。\n",
    "    mfcc_feat_div_div = mfcc_feat_div - np.concatenate((mfcc_feat_div[[0]], mfcc_feat_div[:-1]))\n",
    "    finalfeature = np.concatenate((mfcc_feat, mfcc_feat_div, mfcc_feat_div_div), axis=1)\n",
    "\n",
    "    train_x.append(finalfeature)  # 更新列表。\n",
    "    train_y.append(label)  # 更新列表。\n",
    "\n",
    "# 然后把输入和输出分别处理成矩阵的形式，并且统一输入的长度：\n",
    "yy = preprocessing.LabelBinarizer().fit_transform(train_y)  # 将train_y标签二值化。yy.shape(201,1)\n",
    "train_x = [np.concatenate((i, np.zeros((1561 - i.shape[0], 39)))) for i in train_x]\n",
    "\n",
    "train_x = np.asarray(train_x)  # (201,1561,39)\n",
    "train_y = np.asarray(yy)  # (201,1)\n",
    "print(train_x.shape, train_y.shape)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "train_y=to_categorical(train_y, num_classes=2)  # (201,2)\n",
    "\n",
    "\"\"\"\n",
    "上面的代码会输出\n",
    "\n",
    "((9709, 1561, 39), (9709, 25))\n",
    "分别是训练集和测试集的形状\n",
    "-------(40, 1561, 39) (40, 40)---------\n",
    "把训练集和测试集分开：\n",
    "\"\"\"\n",
    "\n",
    "# 此处修改\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.3, random_state=0)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "x_max=max(np.max(X_train),np.max(X_test)) #112.95\n",
    "\"\"\"\n",
    "上面的代码会输出：\n",
    "((140, 1561, 39), (61, 1561, 39), (140, 2), (61, 2))\n",
    "------(28, 1561, 39) (12, 1561, 39) (28, 40) (12, 40)------\n",
    "所以训练集和测试集分别有6796和2913条数据，然使用keras构建一个1d卷积模型：\n",
    "\"\"\"\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import LSTM, Dense, Activation, SimpleRNN, Conv1D, MaxPool1D, Flatten, Reshape, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.metrics import categorical_accuracy\n",
    "\n",
    "\n",
    "task='evaluate' #train or evaluate or predict\n",
    "if task=='train':\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, 4, input_shape=(300, 39)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool1D(4))\n",
    "    model.add(Conv1D(64, 4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool1D(4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax')) # model.summary()\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[categorical_accuracy])\n",
    "\n",
    "    # 然后训练这个模型：\n",
    "    # early_stopping = EarlyStopping(monitor='val_loss', patience=20)#早停法。\n",
    "    # model.fit(X_train[:, 200:500, :], y_train, validation_data=(X_test[:, 200:500, :], y_test), callbacks=[early_stopping],batch_size=9, epochs=1000)\n",
    "    model.fit(X_train[:, 200:500, :], y_train, validation_data=(X_test[:, 200:500, :], y_test), batch_size=10, epochs=50)\n",
    "\n",
    "    # 模型评估一。\n",
    "    # loss,accuracy = model.evaluate(X_test[:, 200:500, :], y_test, batch_size=16)\n",
    "    # print('\\nModel test loss',loss)\n",
    "    # print('test accuracy',accuracy)\n",
    "\n",
    "    #模型评估二。\n",
    "    # score = model.evaluate(X_test[:, 200:500, :], y_test, verbose = 0)\n",
    "    # print('\\nTest score:',score[0])\n",
    "    # print('Test accuracy:',score[1])\n",
    "\n",
    "    # 保存模型。\n",
    "    model.save('voice_recog.h5') # HDF5文件，pip install h5py。\n",
    "\n",
    "elif task=='evaluate':\n",
    "    model=load_model('voice_recog.h5')\n",
    "    accuracy = model.evaluate(X_test[:, 200:500, :], y_test, batch_size=16)\n",
    "    print('test accuracy:',accuracy)\n",
    "elif task=='predict':\n",
    "    model=load_model('voice_recog.h5')\n",
    "    result=model.predict_on_batch(X_test[:, 200:500, :])\n",
    "    print(result)\n",
    "\n",
    "# 模型可视化。需提前pip install graphviz\\pydot\\libgd\\freetype\\fontconfig\\gperf。\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "# plot_model(model,to_file=\"model.png\",show_shapes=True)\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
